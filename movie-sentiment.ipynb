{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "movie_train = pd.read_csv( \"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "movie_test = pd.read_csv( \"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "movie_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           25000 non-null object\n",
      "sentiment    25000 non-null int64\n",
      "review       25000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n"
     ]
    }
   ],
   "source": [
    "movie_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
       "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
       "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
       "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
       "4   \"12128_7\"  \"A very accurate depiction of small time mob l..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_train.columns\n",
    "movie_train.head()\n",
    "#text = movie_train['review'][0]\n",
    "#text.replace('\\\\', ' ')\n",
    "movie_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c22211b2782c92fbf632efa115972b19afe52d30"
   },
   "outputs": [],
   "source": [
    "# Cleaning the dataset\n",
    "def clean_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r'http\\S+', '', elem))\n",
    "    df[text_field] = df[text_field].apply(lambda elem: elem.replace('<br />', ' '))\n",
    "    df[text_field] = df[text_field].apply(lambda elem: elem.replace('\\\\', ' '))\n",
    "    df[text_field] = df[text_field].apply(lambda elem: elem.replace('_', ' '))\n",
    "    \n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    df[text_field] = df[text_field].apply(lambda elem: elem.translate(remove_digits))\n",
    "    return df\n",
    "\n",
    "clean_movie_train = clean_text(movie_train, 'review')\n",
    "clean_movie_test = clean_text(movie_test, 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e54cbe55663e1c4eb27085abfbf74a2cdb874c39"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "clean_movie_train['tokens'] = clean_movie_train['review'].apply(tokenizer.tokenize)\n",
    "clean_movie_train.head()\n",
    "\n",
    "clean_movie_test['tokens'] = clean_movie_test['review'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "48a84c092834e9fb331f2b8048ed3a5e112fc987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5919546 words total, with a vocabulary size of 73495\n"
     ]
    }
   ],
   "source": [
    "# Explore words and sentences\n",
    "all_words = [word for tokens in clean_movie_train['tokens'] for word in tokens]\n",
    "sentence_lengths = [len(tokens) for tokens in clean_movie_train['tokens']]\n",
    "Vocab = sorted(list(set(all_words)))\n",
    "print('%s words total, with a vocabulary size of %s' %(len(all_words), len(Vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "9ee9f9325559c5225eb793618d19808a18deda8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'aaa', 'aaaaaaah', 'aaaaah', 'aaaaatch', 'aaaahhhhhhh', 'aaaand', 'aaaarrgh', 'aaah', 'aaargh', 'aaaugh', 'aaawwwwnnn', 'aachen', 'aada', 'aadha', 'aag', 'aage', 'aaghh', 'aah', 'aahhh', 'aaip', 'aaja', 'aakash', 'aaker', 'aakrosh', 'aaliyah', 'aames', 'aamir', 'aan', 'aankh', 'aankhen', 'aap', 'aapke', 'aapkey', 'aardman', 'aardvarks', 'aargh', 'aaron', 'aarp', 'aarrrgh', 'aatish', 'aauugghh', 'aavjo', 'aaww', 'ab', 'aback', 'abadi', 'abahy', 'abanazer', 'abandon', 'abandoned', 'abandoning', 'abandonment', 'abandons', 'abanks', 'abas', 'abashed', 'abashidze', 'abatement', 'abating', 'abattoirs', 'abba', 'abbad', 'abbas', 'abbasi', 'abbey', 'abbie', 'abbot', 'abbots', 'abbott', 'abbreviated', 'abbu', 'abby', 'abc', 'abcd', 'abdic', 'abdicates', 'abdicating', 'abdomen', 'abdominal', 'abdu', 'abduct', 'abducted', 'abductee', 'abducting', 'abduction', 'abductions', 'abductor', 'abductors', 'abducts', 'abdul', 'abdullah', 'abe', 'abel', 'abercrombie', 'abernathy', 'aberrant', 'aberration', 'aberrations']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 336755),\n",
       " ('and', 164142),\n",
       " ('a', 163140),\n",
       " ('of', 145865),\n",
       " ('to', 135724),\n",
       " ('is', 107337),\n",
       " ('it', 96471),\n",
       " ('in', 93978),\n",
       " ('i', 87692),\n",
       " ('this', 76007),\n",
       " ('that', 73287),\n",
       " ('s', 65709),\n",
       " ('was', 48209),\n",
       " ('as', 46937),\n",
       " ('for', 44345),\n",
       " ('with', 44130),\n",
       " ('movie', 44046),\n",
       " ('but', 42623),\n",
       " ('film', 40162),\n",
       " ('t', 34390),\n",
       " ('you', 34268),\n",
       " ('on', 34203),\n",
       " ('not', 30634),\n",
       " ('he', 30155),\n",
       " ('are', 29438),\n",
       " ('his', 29376),\n",
       " ('have', 27732),\n",
       " ('be', 26957),\n",
       " ('one', 26795),\n",
       " ('all', 23985),\n",
       " ('at', 23516),\n",
       " ('they', 22916),\n",
       " ('by', 22549),\n",
       " ('an', 21564),\n",
       " ('who', 21442),\n",
       " ('so', 20617),\n",
       " ('from', 20499),\n",
       " ('like', 20281),\n",
       " ('there', 18866),\n",
       " ('her', 18424),\n",
       " ('or', 18008),\n",
       " ('just', 17774),\n",
       " ('about', 17375),\n",
       " ('out', 17113),\n",
       " ('if', 16809),\n",
       " ('has', 16791),\n",
       " ('what', 16168),\n",
       " ('some', 15749),\n",
       " ('good', 15147),\n",
       " ('can', 14678),\n",
       " ('more', 14255),\n",
       " ('she', 14228),\n",
       " ('when', 14184),\n",
       " ('very', 14068),\n",
       " ('up', 13293),\n",
       " ('time', 12727),\n",
       " ('no', 12716),\n",
       " ('even', 12656),\n",
       " ('my', 12504),\n",
       " ('would', 12436),\n",
       " ('which', 12051),\n",
       " ('story', 11990),\n",
       " ('only', 11919),\n",
       " ('really', 11739),\n",
       " ('see', 11479),\n",
       " ('their', 11385),\n",
       " ('had', 11290),\n",
       " ('we', 10865),\n",
       " ('were', 10786),\n",
       " ('me', 10765),\n",
       " ('well', 10668),\n",
       " ('than', 9920),\n",
       " ('much', 9766),\n",
       " ('get', 9312),\n",
       " ('bad', 9308),\n",
       " ('been', 9289),\n",
       " ('people', 9287),\n",
       " ('will', 9211),\n",
       " ('do', 9178),\n",
       " ('other', 9164),\n",
       " ('also', 9159),\n",
       " ('into', 9111),\n",
       " ('first', 9064),\n",
       " ('great', 9061),\n",
       " ('because', 9047),\n",
       " ('how', 8901),\n",
       " ('him', 8879),\n",
       " ('don', 8848),\n",
       " ('most', 8787),\n",
       " ('made', 8364),\n",
       " ('its', 8181),\n",
       " ('then', 8120),\n",
       " ('way', 8026),\n",
       " ('make', 8025),\n",
       " ('them', 7972),\n",
       " ('could', 7923),\n",
       " ('too', 7833),\n",
       " ('movies', 7668),\n",
       " ('any', 7660),\n",
       " ('after', 7638)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore vocabulary\n",
    "print(Vocab[0:100])\n",
    "\n",
    "from collections import Counter\n",
    "count_all_words = Counter(all_words)\n",
    "count_all_words.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "0344153d157bc3c2ad341785ad40020b7525f3ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 73495)\n",
      "(25000, 73495)\n"
     ]
    }
   ],
   "source": [
    "#Embedding 1\n",
    "# TFIDF bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer = 'word', token_pattern = r'\\w+')\n",
    "\n",
    "tfidf = dict()\n",
    "tfidf['all_train'] = (tfidf_vectorizer.fit_transform(clean_movie_train['review']))\n",
    "tfidf['test'] = (tfidf_vectorizer.transform(clean_movie_test['review']))\n",
    "print(tfidf['all_train'].shape)\n",
    "print(tfidf['test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "669daaa07d6cd4771775577c4fd551970cfe941b"
   },
   "outputs": [],
   "source": [
    "#Embedding 2\n",
    "# word2vec \n",
    "#from gensim.models import Word2Vec\n",
    "#model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "3598e6d854e588ce8a7e0124ee4d7062fdf7b129"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  sentiment\n",
       "0  \"12311_10\"          1\n",
       "1    \"8348_2\"          0\n",
       "2    \"5828_4\"          1\n",
       "3    \"7186_2\"          1\n",
       "4   \"12128_7\"          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "train_target = clean_movie_train['sentiment']\n",
    "classifier.fit(tfidf['all_train'], train_target)\n",
    "\n",
    "submission = pd.DataFrame.from_dict({'id': clean_movie_test['id']})\n",
    "lr_predict = classifier.predict(tfidf['test'])\n",
    "\n",
    "submission = pd.DataFrame(data={\"id\":clean_movie_test[\"id\"], \"sentiment\":lr_predict})\n",
    "submission.head()\n",
    "#submission.to_csv( \"submission.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
